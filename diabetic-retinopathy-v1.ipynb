{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":952401,"sourceType":"datasetVersion","datasetId":517172}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/yahyasoker/diabetic-retinopathy-v1?scriptVersionId=249932563\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom scipy.signal import spectrogram\nfrom tqdm import tqdm\nimport random\nimport shutil\nimport seaborn as sns\nimport warnings\nfrom PIL import Image\nimport numpy as np\nfrom glob import glob\n#---------------------------------------\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\n#---------------------------------------\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Input, BatchNormalization, Add\nfrom tensorflow.keras.optimizers import Adamax\nfrom tensorflow.keras.metrics import Precision, Recall\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping\n#---------------------------------------\nfrom sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, ConfusionMatrixDisplay\nfrom sklearn.model_selection import KFold\n#---------------------------------------\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:30:42.81209Z","iopub.execute_input":"2025-05-04T17:30:42.812362Z","iopub.status.idle":"2025-05-04T17:30:56.614209Z","shell.execute_reply.started":"2025-05-04T17:30:42.812338Z","shell.execute_reply":"2025-05-04T17:30:56.61361Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to move files to respective directories with progress bar\ndef move_files(file_paths, labels, target_dirs):\n    with tqdm(total=len(file_paths), desc=\"Moving Files\", bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt}\") as pbar:\n        for file_path, label in zip(file_paths, labels):\n            target_dir = target_dirs[label]\n            shutil.copy(file_path, target_dir)\n            pbar.update(1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:30:56.615437Z","iopub.execute_input":"2025-05-04T17:30:56.61597Z","iopub.status.idle":"2025-05-04T17:30:56.620132Z","shell.execute_reply.started":"2025-05-04T17:30:56.615944Z","shell.execute_reply":"2025-05-04T17:30:56.619427Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def data_prep_split(input_dir, output_dir, classes):\n    # Define output directories\n    train_dir = os.path.join(output_dir, \"train\")\n    valid_dir = os.path.join(output_dir, \"valid\")\n    test_dir = os.path.join(output_dir, \"test\")\n\n    # Create directories for each class in each split\n    split_dirs = {\n        'train': {},\n        'valid': {},\n        'test': {}\n    }\n\n    for split in split_dirs:\n        for class_name in classes:\n            path = os.path.join(output_dir, split, class_name)\n            os.makedirs(path, exist_ok=True)\n            split_dirs[split][class_name] = path\n\n    # Process each class\n    for label, class_name in enumerate(classes):\n        class_dir = os.path.join(input_dir, class_name)\n        class_files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n                       if os.path.isfile(os.path.join(class_dir, file))]\n\n        # Shuffle the files\n        random.shuffle(class_files)\n\n        # Compute split indices\n        total = len(class_files)\n        train_end = int(0.7 * total)\n        valid_end = train_end + int(0.1 * total)\n\n        train_files = class_files[:train_end]\n        valid_files = class_files[train_end:valid_end]\n        test_files = class_files[valid_end:]\n\n        # Move files\n        move_files(train_files, [label] * len(train_files), list(split_dirs['train'].values()))\n        move_files(valid_files, [label] * len(valid_files), list(split_dirs['valid'].values()))\n        move_files(test_files, [label] * len(test_files), list(split_dirs['test'].values()))\n\n    print(\"Data successfully split into train, validation, and test directories.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:30:56.621028Z","iopub.execute_input":"2025-05-04T17:30:56.621239Z","iopub.status.idle":"2025-05-04T17:30:56.655481Z","shell.execute_reply.started":"2025-05-04T17:30:56.62122Z","shell.execute_reply":"2025-05-04T17:30:56.654786Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to create a DataFrame for training/testing data\ndef create_df(data_path):\n    classes, class_paths = zip(*[\n        (label, os.path.join(data_path, label, file))\n        for label in os.listdir(data_path) if os.path.isdir(os.path.join(data_path, label))\n        for file in os.listdir(os.path.join(data_path, label))\n    ])\n    df = pd.DataFrame({'Class Path': class_paths, 'Class': classes})\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:30:56.657153Z","iopub.execute_input":"2025-05-04T17:30:56.657636Z","iopub.status.idle":"2025-05-04T17:30:56.673396Z","shell.execute_reply.started":"2025-05-04T17:30:56.657619Z","shell.execute_reply":"2025-05-04T17:30:56.672868Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"input_dir = \"/kaggle/input/diabetic-retinopathy-224x224-gaussian-filtered/gaussian_filtered_images/gaussian_filtered_images\"  # Parent directory containing folders A, B, C, D, E\noutput_dir = \"/kaggle/working/\"      # Directory where you want to store the processed data\nclasses = ['Mild','Moderate','No_DR','Proliferate_DR','Severe']\n# Prepare data with an 80-20 split\ndata_prep_split(input_dir, output_dir,classes)\n\n# Create DataFrames for train and test data\ntrain_path = os.path.join(output_dir, \"train\")\ntest_path = os.path.join(output_dir, \"test\")\nvalid_path = os.path.join(output_dir, \"valid\")\n\n\ntrain_df = create_df(train_path)\ntest_df = create_df(test_path)\nvalid_df = create_df(valid_path)\n\n# Display DataFrames\nprint(\"Training DataFrame:\")\nprint(train_df.head())\n\nprint(\"\\nTesting DataFrame:\")\nprint(test_df.head())\n\nprint(\"\\nValid DataFrame:\")\nprint(valid_df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:30:56.673964Z","iopub.execute_input":"2025-05-04T17:30:56.674163Z","iopub.status.idle":"2025-05-04T17:31:31.851344Z","shell.execute_reply.started":"2025-05-04T17:30:56.674148Z","shell.execute_reply":"2025-05-04T17:31:31.850555Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_dff(tr_path):\n    classes, class_paths = zip(*[(label, os.path.join(tr_path, label, image))\n                                 for label in os.listdir(tr_path) if os.path.isdir(os.path.join(tr_path, label))\n                                 for image in os.listdir(os.path.join(tr_path, label))])\n\n    tr_df = pd.DataFrame({'Class Path': class_paths, 'Class': classes})\n    return tr_df\ndef test_dff(ts_path):\n    classes, class_paths = zip(*[(label, os.path.join(ts_path, label, image))\n                                 for label in os.listdir(ts_path) if os.path.isdir(os.path.join(ts_path, label))\n                                 for image in os.listdir(os.path.join(ts_path, label))])\n\n    ts_df = pd.DataFrame({'Class Path': class_paths, 'Class': classes})\n    return ts_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:31:31.852145Z","iopub.execute_input":"2025-05-04T17:31:31.852524Z","iopub.status.idle":"2025-05-04T17:31:31.857758Z","shell.execute_reply.started":"2025-05-04T17:31:31.852503Z","shell.execute_reply":"2025-05-04T17:31:31.857143Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def data_df(train_path,test_path):\n    train_df = train_dff(train_path)\n    test_df = test_dff(test_path)\n    valid_df, test_df = train_test_split(test_df, train_size=0.5, random_state=41, stratify=test_df['Class'])\n    \n    datasets = [(\"Train Data\", train_df['Class']), (\"Test Data\", test_df['Class']),(\"Validation Data\", valid_df['Class'])]\n    palettes = ['crest', 'mako', 'rocket', 'flare']\n\n# Loop through each dataset and create the corresponding plot\n    for i, (title, data) in enumerate(datasets):\n        plt.figure(figsize=(4, 3))\n        ax = sns.countplot(y=data, palette=palettes[i % len(palettes)])\n        ax.set(xlabel='', ylabel='', title=f'Count of images in each class ({title})')\n        ax.bar_label(ax.containers[0], fontsize=10, padding=5)\n        plt.show()\n    return train_df,test_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:31:31.858467Z","iopub.execute_input":"2025-05-04T17:31:31.859254Z","iopub.status.idle":"2025-05-04T17:31:31.877246Z","shell.execute_reply.started":"2025-05-04T17:31:31.859236Z","shell.execute_reply":"2025-05-04T17:31:31.876608Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_path = \"/kaggle/working/train\"\ntest_path = \"/kaggle/working/test\"\ntrain_df, test_df = data_df(train_path,test_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:31:31.878066Z","iopub.execute_input":"2025-05-04T17:31:31.878324Z","iopub.status.idle":"2025-05-04T17:31:32.371341Z","shell.execute_reply.started":"2025-05-04T17:31:31.878298Z","shell.execute_reply":"2025-05-04T17:31:32.370765Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_model(img_shape, ml,y):\n    \"\"\"\n    Create a model with a dynamic base model from TensorFlow's application models.\n\n    Parameters:\n    - img_shape: tuple, shape of the input images (e.g., (224, 224, 3))\n    - ml: TensorFlow application model function (e.g., tf.keras.applications.VGG16)\n    \n    Returns:\n    - Compiled Keras Model\n    \"\"\"\n    # Input layer\n    inputs = Input(shape=img_shape)  # Define the input layer based on img_shape\n    \n    # Base model\n    base_model = ml(\n        include_top=False,\n        weights=\"imagenet\",\n        input_shape=img_shape,  # Define the input shape for the base model\n        pooling='max'  # Use global max pooling\n    )\n    \n    # Connect the base model to the inputs\n    x = base_model(inputs, training=False)  # Use the base model's features without updating weights\n    \n    # Flatten Layer\n    x = Flatten()(x)  # Flatten the output of the base model\n\n    # First Dropout Layer\n    x = Dropout(rate=0.3)(x)\n\n    # First Dense Layer\n    x = Dense(128, activation='relu')(x)\n\n    # Second Dropout Layer\n    x = Dropout(rate=0.25)(x)\n\n    # Output Layer\n    outputs = Dense(y, activation='sigmoid')(x)\n\n    # Create the model\n    model = Model(inputs=inputs, outputs=outputs)\n\n    # Compile the model\n    model.compile(\n        optimizer=Adamax(learning_rate=0.001),\n        loss='categorical_crossentropy',\n        metrics=['accuracy', Precision(), Recall()]\n    )\n\n    model.summary()  # Display model summary\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:31:32.37195Z","iopub.execute_input":"2025-05-04T17:31:32.372125Z","iopub.status.idle":"2025-05-04T17:31:32.378084Z","shell.execute_reply.started":"2025-05-04T17:31:32.372111Z","shell.execute_reply":"2025-05-04T17:31:32.377451Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_training_metrics(epochs, training_metrics, validation_metrics, title, xlabel, ylabel, best_index, best_value, best_label):\n    \"\"\"\n    Plots training and validation metrics over epochs with an emphasis on the best value.\n    \"\"\"\n    if len(training_metrics) == 0 or len(validation_metrics) == 0:\n        print(\"Error: Training or validation metrics are empty.\")\n        return\n    \n    # Create the plot\n    plt.figure(figsize=(12, 6))  # Larger figure for more space\n    plt.plot(epochs, training_metrics, 'r-', label='Training', linewidth=2, markersize=6)\n    plt.plot(epochs, validation_metrics, 'g-', label='Validation', linewidth=2, markersize=6)\n    \n    # Add a scatter for the best value\n    plt.scatter(best_index + 1, best_value, s=200, c='blue', edgecolor='black', label=f'{best_label} ({best_value:.4f})', zorder=5)\n    \n    # Annotate the best value point\n    plt.text(best_index + 1, best_value + 0.05, f'{best_value:.4f}', color='blue', ha='center', fontsize=12, fontweight='bold')\n\n    # Add horizontal line at best value to emphasize it\n    plt.axhline(y=best_value, color='blue', linestyle='--', linewidth=1.5, alpha=0.6)\n\n    # Title and labels\n    plt.title(title, fontsize=16, fontweight='bold')\n    plt.xlabel(xlabel, fontsize=14)\n    plt.ylabel(ylabel, fontsize=14)\n\n    # Enhance legend\n    plt.legend(fontsize=12, loc='upper right', title=\"Metrics\", title_fontsize=14)\n\n    # Grid for better readability\n    plt.grid(True, linestyle='--', alpha=0.6)\n\n    # Customize ticks for better clarity\n    plt.xticks(fontsize=12)\n    plt.yticks(fontsize=12)\n\n    # Tight layout to avoid clipping\n    plt.tight_layout()\n\n    # Show the plot\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:31:32.380244Z","iopub.execute_input":"2025-05-04T17:31:32.3805Z","iopub.status.idle":"2025-05-04T17:31:32.396357Z","shell.execute_reply.started":"2025-05-04T17:31:32.380477Z","shell.execute_reply":"2025-05-04T17:31:32.395664Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_confusion_matrix(y_true, y_pred_classes, test_gen, fold_idx):\n    \"\"\"\n    Plots a confusion matrix and displays evaluation metrics.\n    \n    Parameters:\n        y_true (list or array-like): True labels.\n        y_pred_classes (list or array-like): Predicted labels.\n        test_gen (object): Test data generator, used to extract class labels.\n        fold_idx (int): Fold index for display purposes.\n    \"\"\"\n    # Generate the confusion matrix\n    cm = confusion_matrix(y_true, y_pred_classes)\n\n    # Set a larger figure size and create an axis\n    fig, ax = plt.subplots(figsize=(12, 10))  # Adjust dimensions as needed\n\n    # Plot the confusion matrix on the specified axis\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=test_gen.class_indices.keys())\n    disp.plot(cmap='Blues', ax=ax)  # Assign ax to ensure resizing\n\n    # Calculate evaluation metrics\n    accuracy = accuracy_score(y_true, y_pred_classes)\n    precision = precision_score(y_true, y_pred_classes, average='micro')\n    recall = recall_score(y_true, y_pred_classes, average='micro')\n    f1 = f1_score(y_true, y_pred_classes, average='micro')\n\n    # Customize plot title and display metrics below the plot\n    plt.title(f\"Confusion Matrix - Fold {fold_idx}\", fontsize=16)\n    plt.figtext(\n        0.5, -0.1,\n        f\"Accuracy: {accuracy:.4f} | Precision: {precision:.4f} | Recall: {recall:.4f} | F1 Score: {f1:.4f}\",\n        ha=\"center\", fontsize=14, color=\"black\"\n    )\n\n    # Show the plot with the updated size\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:31:32.396941Z","iopub.execute_input":"2025-05-04T17:31:32.397168Z","iopub.status.idle":"2025-05-04T17:31:32.41398Z","shell.execute_reply.started":"2025-05-04T17:31:32.397149Z","shell.execute_reply":"2025-05-04T17:31:32.413379Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def automated_model_training_with_plots(train_df, test_df, kf, img_size, batch_size, img_shape, model_list,epoch_size,y):\n    \"\"\"\n    Automates training and evaluation with different pre-trained models, including plotting metrics.\n\n    Parameters:\n    - train_df: DataFrame with training data\n    - test_df: DataFrame with test data\n    - kf: KFold cross-validator\n    - img_size: Tuple, target size for the images\n    - batch_size: Integer, batch size for data generators\n    - img_shape: Tuple, input shape for the model\n    - model_list: List of TensorFlow model functions (e.g., [VGG16, Xception])\n\n    Outputs:\n    - Training metrics, plots, and confusion matrix for each model.\n    \"\"\"\n    for model_fn in model_list:\n        print(f\"Training with model: {model_fn.__name__}\")\n        \n        # Initialize metrics storage\n        accuracy_scores, precision_scores, recall_scores, f1_scores = [], [], [], []\n        \n        # K-Fold Cross Validation Loop\n        for fold_idx, (train_index, val_index) in enumerate(kf.split(train_df)):\n            print(f\"\\nFold {fold_idx + 1}/{kf.n_splits}\")\n            \n            # Split data into training and validation sets\n            train_data = train_df.iloc[train_index]\n            val_data = train_df.iloc[val_index]\n\n            # Data generators\n            train_gen = ImageDataGenerator(rescale=1/255, brightness_range=(0.8, 1.2)).flow_from_dataframe(\n                train_data, x_col='Class Path', y_col='Class', batch_size=batch_size, target_size=img_size)\n            \n            valid_gen = ImageDataGenerator(rescale=1/255).flow_from_dataframe(\n                val_data, x_col='Class Path', y_col='Class', batch_size=batch_size, target_size=img_size)\n            \n            test_gen = ImageDataGenerator(rescale=1/255).flow_from_dataframe(\n                test_df, x_col='Class Path', y_col='Class', batch_size=16, target_size=img_size, shuffle=False)\n\n            # Build and train model\n            model = create_model(img_shape, model_fn,y)\n            history = model.fit(train_gen, validation_data=valid_gen, epochs=epoch_size, shuffle=False)\n\n            # Extract training and validation metrics\n            training_accuracy = history.history['accuracy']\n            validation_accuracy = history.history['val_accuracy']\n            training_loss = history.history['loss']\n            validation_loss = history.history['val_loss']\n\n            # Find best epoch indices\n            best_epoch_loss_index = np.argmin(validation_loss)\n            best_validation_loss = validation_loss[best_epoch_loss_index]\n            best_epoch_accuracy_index = np.argmax(validation_accuracy)\n            best_validation_accuracy = validation_accuracy[best_epoch_accuracy_index]\n\n            # Plot training metrics\n            epochs = np.arange(1, len(training_accuracy) + 1)\n            plot_training_metrics(\n                epochs,\n                training_accuracy,\n                validation_accuracy,\n                \"Training and Validation Accuracy\",\n                \"Epochs\",\n                \"Accuracy\",\n                best_epoch_accuracy_index,\n                best_validation_accuracy,\n                f\"Best Epoch = {best_epoch_accuracy_index + 1}\"\n            )\n            plot_training_metrics(\n                epochs,\n                training_loss,\n                validation_loss,\n                \"Training and Validation Loss\",\n                \"Epochs\",\n                \"Loss\",\n                best_epoch_loss_index,\n                best_validation_loss,\n                f\"Best Epoch = {best_epoch_loss_index + 1}\"\n            )\n\n            # Evaluate the model on test data\n            y_true = test_gen.classes\n            y_pred = model.predict(test_gen)\n            y_pred_classes = np.argmax(y_pred, axis=1)\n\n            # Metrics\n            accuracy = accuracy_score(y_true, y_pred_classes)\n            precision = precision_score(y_true, y_pred_classes, average='macro')\n            recall = recall_score(y_true, y_pred_classes, average='macro')\n            f1 = f1_score(y_true, y_pred_classes, average='macro')\n\n            # Append metrics\n            accuracy_scores.append(accuracy)\n            precision_scores.append(precision)\n            recall_scores.append(recall)\n            f1_scores.append(f1)\n\n            # Confusion Matrix\n            plot_confusion_matrix(y_true,\n                y_pred_classes,\n                test_gen, \n                fold_idx)\n\n        # Print cross-validation metrics\n        print(f\"\\nResults for model: {model_fn.__name__}\")\n        print(f\"Accuracy: {np.mean(accuracy_scores):.4f} ± {np.std(accuracy_scores):.4f}\")\n        print(f\"Precision: {np.mean(precision_scores):.4f} ± {np.std(precision_scores):.4f}\")\n        print(f\"Recall: {np.mean(recall_scores):.4f} ± {np.std(recall_scores):.4f}\")\n        print(f\"F1 Score: {np.mean(f1_scores):.4f} ± {np.std(f1_scores):.4f}\")\n        print(\"-\" * 50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:31:32.414622Z","iopub.execute_input":"2025-05-04T17:31:32.414782Z","iopub.status.idle":"2025-05-04T17:31:32.432678Z","shell.execute_reply.started":"2025-05-04T17:31:32.414768Z","shell.execute_reply":"2025-05-04T17:31:32.432048Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"kf = KFold(n_splits=3, shuffle=True, random_state=42) \nimg_size = (256, 256)\nimg_shape = (256,256,3)\nbatch_size = 32\nloss_threshold=1.5\npatience=10\nepoch_size = 30\ny = 5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:31:32.433381Z","iopub.execute_input":"2025-05-04T17:31:32.433551Z","iopub.status.idle":"2025-05-04T17:31:32.450462Z","shell.execute_reply.started":"2025-05-04T17:31:32.433525Z","shell.execute_reply":"2025-05-04T17:31:32.449758Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Example usage\nmodels_to_evaluate = [tf.keras.applications.Xception, tf.keras.applications.VGG16, tf.keras.applications.ResNet50]\nautomated_model_training_with_plots(train_df, test_df, kf, img_size, batch_size, img_shape, models_to_evaluate,epoch_size,y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:31:32.451172Z","iopub.execute_input":"2025-05-04T17:31:32.451511Z","iopub.status.idle":"2025-05-04T18:55:46.731489Z","shell.execute_reply.started":"2025-05-04T17:31:32.451486Z","shell.execute_reply":"2025-05-04T18:55:46.730661Z"}},"outputs":[],"execution_count":null}]}